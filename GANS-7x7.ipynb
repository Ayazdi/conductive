{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conductive.ai Take-home assignment\n",
    "\n",
    "## Description:\n",
    "A semiconductor fab is performing a SATEOS CVD process on 4 different AMAT PRODUCER SE tools.\n",
    "\n",
    "They have performed Design of Experiments on 500 300mm wafers by varying 3 process parameters:\n",
    "\n",
    "- Flowfactor: inversely proportional to TEOS (precursor) flow. Actual flow value not accessible at the moment.\n",
    "- Spacing: distance between shower head and wafer.\n",
    "- Deposition Time.\n",
    "\n",
    "Temperature was held constant at 480 celsius. The fab wants to know how would film thickness change if they would change the temperature in the range of 460-500 celsius.\n",
    "\n",
    "They chose 125 parameter combinations (recipes) and performed each of them on 4 different tools to account for tool variation.\n",
    "\n",
    "Film thickness values were measured (in angstrom) at 49 specific points on the wafer (sites). The spec is 1500Ã….\n",
    "\n",
    "Coordinates of the sites are given in a separate file. Values are in micrometers, (0,0) is the center of the wafer.\n",
    "\n",
    "### Task:\n",
    " - Reconstruct wafer profile images from sites using interpolation.\n",
    " - Build a generative machine learning model (VAE, GAN, or similar) that predicts the thickness profile of the wafer based on flowfactor, spacing, deposition time, and tool.\n",
    " - Ensure that the machine learning model is capable of extrapolating 1 standard deviation outside of the ranges of parameters in accordance with physics.\n",
    "\n",
    "- (Bonus) Build a physics-based model (preferably using simulations) for this process that would include temperature. If you need information on other process parameters, we'd be happy to provide them if available. Adapt it to fit the data. Combine it with the ML model to incorporate the influence of temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, LeakyReLU, ReLU, Flatten, Dropout, Dense, Reshape, Conv2DTranspose, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta\n",
    "from tensorflow.keras.layers import Input, Embedding, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import Mean\n",
    "import tensorflow as tf\n",
    "# from tensorflow import InteractiveSession\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.pyplot import figure, imshow, axis\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('aug_df.csv',)\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['FLOWFACTOR', 'SPACING', 'DEP TIME', 'TOOL']\n",
    "all_sites = df.columns.drop(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining weights of the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_COLUMNS = ['FLOWFACTOR', 'SPACING', 'DEP TIME']\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "y = df[Y_COLUMNS]\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "tsne=TSNE()\n",
    "y_tsne = tsne.fit_transform(y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of bins per each extrinsic properties\n",
    "BINS=6\n",
    "\n",
    "for Y_column in Y_COLUMNS:\n",
    "    print(Y_column)\n",
    "    fig, axs= plt.subplots(1,2, figsize=(7,3))\n",
    "    im=axs[0].scatter(y_tsne[:,0], y_tsne[:,1], c= df[Y_column]);\n",
    "    h=axs[1].hist(df[Y_column], bins=BINS)\n",
    "    plt.show()\n",
    "\n",
    "binning_labels_dict={}\n",
    "binning_labels_dict['TOOL_binning'] = df['TOOL'].values\n",
    "\n",
    "Y_COLUMNS_BINNING=['TOOL_binning']\n",
    "for Y_column in Y_COLUMNS:\n",
    "    cnt, bins = np.histogram(df[Y_column], bins=BINS)\n",
    "    bins[0] -= 1\n",
    "    col_name = Y_column + \"_binning\"\n",
    "    binning_labels_dict[col_name] = np.searchsorted(bins, df[Y_column].values)\n",
    "    Y_COLUMNS_BINNING.append(col_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_df = pd.DataFrame(binning_labels_dict)#.groupby(col_name).count()\n",
    "binning_df[\"T\"] = 1\n",
    "count_bins_df = binning_df.groupby(Y_COLUMNS_BINNING).count()\n",
    "max_count = count_bins_df[\"T\"].max()\n",
    "\n",
    "df = pd.concat((df,binning_df),axis=1)\n",
    "df = df.drop(\"T\",axis=1)\n",
    "count_bins_df = count_bins_df.reset_index()\n",
    "df = pd.merge(df,count_bins_df,on=Y_COLUMNS_BINNING)\n",
    "df[\"weight\"] = max_count/df[\"T\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding of TOOL feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['TOOL'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_COLUMNS = ['FLOWFACTOR', 'SPACING', 'DEP TIME', 'TOOL_1', 'TOOL_2', 'TOOL_3', 'TOOL_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preproccesing and rescaling for the model\n",
    "\n",
    "The thickness profile array with the shape of (49,) reshaped to a 7x7 matrix for the convolutional networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=16\n",
    "batch_count = int(np.ceil(len(df)/BATCH_SIZE))\n",
    "\n",
    "WEIGHTS=[]\n",
    "\n",
    "# reshape the thickness array to 7x7 matrix and rescale\n",
    "scaler_x = MinMaxScaler((-1,1))\n",
    "XS_scaled = scaler_x.fit_transform(df[all_sites])\n",
    "XS_scaled = XS_scaled.reshape(15500, 7, 7)\n",
    "\n",
    "scaler_y_2 = MinMaxScaler((-1,1))\n",
    "YS = np.array(df[Y_COLUMNS]) #for testing the model only\n",
    "YS_scaled = scaler_y_2.fit_transform(df[Y_COLUMNS])\n",
    "\n",
    "for b in range(0, batch_count):\n",
    "#     print(b * BATCH_SIZE,\"->\",min(len(df), b * BATCH_SIZE+BATCH_SIZE) - 1)\n",
    "    batch_indices = np.arange(b * BATCH_SIZE, min(len(df), b * BATCH_SIZE + BATCH_SIZE))\n",
    "    for ind in batch_indices:              \n",
    "         WEIGHTS.append(df.loc[ind,\"weight\"])\n",
    "        \n",
    "\n",
    "WEIGHTS = np.array(WEIGHTS)\n",
    "dataset=(XS_scaled, YS_scaled, WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE=(7, 7, 1)\n",
    "EXTRINSIC_DIM = 7 #LABELS, Y\n",
    "latent_dim = 32 # need to confirm\n",
    "LATENT_DIM = latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone discriminator model\n",
    "# @tf.function\n",
    "def define_cond_discriminator(in_shape=INPUT_SHAPE, n_classes=EXTRINSIC_DIM):    \n",
    "    # label input\n",
    "    in_label = Input(shape=(EXTRINSIC_DIM,), name=\"Y_extrinsic\")\n",
    "    # scale up to image dimensions with linear activation\n",
    "    n_nodes = in_shape[0] * in_shape[1]\n",
    "\n",
    "    li = Dense(n_nodes)(in_label)\n",
    "\n",
    "    # reshape to additional channel\n",
    "    li = Reshape((in_shape[0], in_shape[1], 1))(li)\n",
    "\n",
    "    # image input\n",
    "    in_image = Input(shape=in_shape, name=\"X\")\n",
    "    # concat label as a channel\n",
    "    merge = Concatenate()([in_image, li])\n",
    "    # downsample\n",
    "    fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(merge)\n",
    "#     fe = BatchNormalization()(fe)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "#     fe = Dropout(0.3)(fe)\n",
    "    # downsample\n",
    "    fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "#     fe = BatchNormalization()(fe)\n",
    "    # flatten feature maps\n",
    "    fe = Flatten()(fe)\n",
    "    # dropout\n",
    "    fe = Dropout(0.4)(fe)\n",
    "    # output\n",
    "    out_layer = Dense(1, activation='sigmoid',name=\"Discriminator\")(fe)\n",
    "    # define model\n",
    "    model = Model([in_image, in_label], out_layer)\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.00001, beta_1=0.5)\n",
    "    #opt = Adadelta()\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_model = define_cond_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# define the standalone generator model\n",
    "def define_cond_generator(latent_dim=LATENT_DIM, n_classes=EXTRINSIC_DIM):\n",
    "    init_size=(7, 7)\n",
    "\n",
    "    # label input\n",
    "    in_label = Input(shape=(EXTRINSIC_DIM,), name=\"Y_extrinsic\")\n",
    "    # linear multiplication\n",
    "    n_nodes = init_size[0] * init_size[1]\n",
    "    li = Dense(n_nodes)(in_label)\n",
    "#     li = BatchNormalization()(li)\n",
    "#     li = Dropout(0.3)(li)\n",
    "\n",
    "    # reshape to additional channel\n",
    "    li = Reshape((init_size[0] , init_size[1], 1))(li)\n",
    "\n",
    "    # image generator input\n",
    "    in_lat = Input(shape=(latent_dim,), name=\"Z_latent\")\n",
    "    # foundation for 7x7 image\n",
    "    n_nodes = 128 * n_nodes\n",
    "    gen = Dense(n_nodes)(in_lat)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = BatchNormalization()(gen)\n",
    "    gen = Dropout(0.5)(gen)\n",
    "    \n",
    "    gen = Reshape((init_size[0], init_size[1], 128))(gen)\n",
    "\n",
    "    # merge image gen and label input\n",
    "    merge = Concatenate()([gen, li])\n",
    "   \n",
    "#     gen = Conv2DTranspose(128, (3,3), strides=(1,1), padding='same')(merge)\n",
    "#     gen = LeakyReLU(alpha=0.2)(gen)\n",
    "#     gen = BatchNormalization()(gen)\n",
    "#     gen = Dropout(0.2)(gen)\n",
    "\n",
    "#     gen = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same')(gen)\n",
    "#     gen = LeakyReLU(alpha=0.2)(gen)\n",
    "#     gen = BatchNormalization()(gen)\n",
    "#     gen = Dropout(0.2)(gen)\n",
    "    \n",
    "#     gen = Conv2D(128, (3,3), strides=(2,2), padding='same')(gen)\n",
    "#     gen = BatchNormalization()(gen)\n",
    "#     gen = LeakyReLU(alpha=0.2)(gen)\n",
    "# #     fe = Dropout(0.3)(fe)\n",
    "#     # downsample\n",
    "#     gen = Conv2D(128, (3,3), strides=(2,2), padding='same')(gen)\n",
    "#     gen = LeakyReLU(alpha=0.2)(gen)\n",
    "#     gen = BatchNormalization()(gen)\n",
    "    \n",
    "#     gen = Reshape((5, 10, 1))(gen)\n",
    "\n",
    "    # output\n",
    "    out_layer = Conv2D(1, (7, 7),activation='tanh', padding='same', name=\"X_generated\")(gen)\n",
    "\n",
    "    # define model\n",
    "    model = Model([in_lat, in_label], out_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_model = define_cond_generator()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine generator and discriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_cond_gan(g_model, d_model):\n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # get noise and label inputs from generator model\n",
    "    gen_noise, gen_label = g_model.input\n",
    "    # get image output from the generator model\n",
    "    gen_output = g_model.output\n",
    "    # connect image output and label input from generator as inputs to discriminator\n",
    "    gan_output = d_model([gen_output, gen_label])\n",
    "    # define gan model as taking noise and label and outputting a classification\n",
    "    model = Model([gen_noise, gen_label], gan_output)\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = define_cond_gan(generator_model, discriminator_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Real and Fake Samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # split into vector and labels\n",
    "    vector, labels, weights = dataset\n",
    "    # choose random instances\n",
    "    ix = np.random.randint(0, vector.shape[0]-1, n_samples) # n_samples were removed I dunno why\n",
    "    # select vector and labels\n",
    "    X, labels, weights = vector[ix], labels[ix], weights[ix]\n",
    "    # generate class labels\n",
    "    y = np.ones((n_samples, 1))\n",
    "    return [X, labels], y, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples, n_classes=EXTRINSIC_DIM):\n",
    "    # generate points in the latent space\n",
    "    x_input = np.random.randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    z_input = x_input.reshape(n_samples, latent_dim)\n",
    "    # generate labels\n",
    "    labels = np.random.choice(len(YS_scaled), size=n_samples)\n",
    "    weights = WEIGHTS[labels]\n",
    "    labels= YS_scaled[labels]    \n",
    "    return z_input, labels, weights\n",
    "\n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    z_input, labels_input, weights_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    images = generator.predict([z_input, labels_input])\n",
    "    # create class labels\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    return [images, labels_input], y, weights_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainig the GAN model function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for trainining of generator and discriminator\n",
    "def train_cgan(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=32, verbose_freq=10, n_batch=32):\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    \n",
    "    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "\n",
    "    # manually enumerate epochs\n",
    "    d_loss1_epochs=[]\n",
    "    d_loss2_epochs=[]\n",
    "    g_loss_epochs=[]\n",
    "    d_loss1_batch=[]\n",
    "    d_loss2_batch=[]\n",
    "    g_loss_batch=[]\n",
    "    \n",
    "    \n",
    "    # manually enumerate epochs\n",
    "    iteration=0\n",
    "    for i in range(n_epochs):\n",
    "        # enumerate batches over the training set\n",
    "        for j in range(bat_per_epo):\n",
    "            # get randomly selected 'real' samples\n",
    "            [X_real, labels_real], y_real, weights_real = generate_real_samples(dataset, half_batch)\n",
    "            # update discriminator model weights\n",
    "            d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real,) # sample_weight=weights_real)\n",
    "            # generate 'fake' examples\n",
    "            [X_fake, labels], y_fake, weights_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            # update discriminator model weights\n",
    "            d_loss2, _ = d_model.train_on_batch([X_fake, labels], y_fake,)#sample_weight=weights_fake)\n",
    "            # prepare points in latent space as input for the generator\n",
    "            z_input, labels_input, weights_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            # create inverted labels for the fake samples\n",
    "            y_gan = np.ones((n_batch, 1))\n",
    "            # update the generator via the discriminator's error\n",
    "            g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan,) #sample_weight=weights_gan)\n",
    "            \n",
    "            d_loss1_batch.append(d_loss1)\n",
    "            d_loss2_batch.append(d_loss2)\n",
    "            g_loss_batch.append(g_loss)\n",
    "        \n",
    "\n",
    "            # visualizing the training steps\n",
    "            if (iteration%verbose_freq==0):\n",
    "                if ax.lines:\n",
    "                    epochs_x = (np.arange(len(d_loss2_batch))+1)/bat_per_epo\n",
    "                    for line,ydata in zip(ax.lines,[d_loss1_batch, d_loss2_batch,g_loss_batch]):\n",
    "                        line.set_xdata(epochs_x)\n",
    "                        line.set_ydata(ydata) \n",
    "                    ax.set_xlim(0,max(epochs_x) + 1/bat_per_epo)\n",
    "                    ax.set_ylim(0.9 * min([min(d_loss1_batch), min(d_loss2_batch), min(g_loss_batch)]), 1.1 * max([max(d_loss1_batch), max(d_loss2_batch), max(g_loss_batch)]))\n",
    "                else:\n",
    "                    ax.plot(d_loss1_batch, label=\"d_loss_real\")\n",
    "                    ax.plot(d_loss2_batch, label=\"d_loss_fake\")\n",
    "                    ax.plot(g_loss_batch, label=\"g_loss\")                 \n",
    "                    fig.legend()\n",
    "                fig.canvas.draw()\n",
    "                \n",
    "            iteration += 1\n",
    "            \n",
    "    if ax.lines:        \n",
    "        epochs_x=(np.arange(len(d_loss2_batch))+1)/bat_per_epo\n",
    "        for line,ydata in zip(ax.lines,[d_loss1_batch, d_loss2_batch,g_loss_batch]):\n",
    "            line.set_xdata(epochs_x)\n",
    "            line.set_ydata(ydata) \n",
    "        ax.set_xlim(0,max(epochs_x)+1/bat_per_epo)\n",
    "        ax.set_ylim(0.9*min([min(d_loss1_batch),min(d_loss2_batch),min(g_loss_batch)]),1.1*max([max(d_loss1_batch), max(d_loss2_batch), max(g_loss_batch)]))\n",
    "    else:\n",
    "        ax.plot(d_loss1_batch, label=\"d_loss_real\")\n",
    "        ax.plot(d_loss2_batch, label=\"d_loss_fake\")\n",
    "        ax.plot(g_loss_batch, label=\"g_loss\")                 \n",
    "        fig.legend()\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process vector from the inputs and visualization functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_process_vector(features):\n",
    "    features = np.array(features).reshape(1, -1)\n",
    "    process_vector = scaler_y_2.transform(features)\n",
    "    return process_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "def visualize(thickness):\n",
    "    site = pd.read_csv('site_coordinates.csv')\n",
    "    site['SITE_Z'] = thickness\n",
    "    points2D = np.vstack([site['SITE_X'], site['SITE_Y']]).T\n",
    "    tri = Delaunay(points2D)\n",
    "    simplices = tri.simplices\n",
    "\n",
    "    fig = ff.create_trisurf(site['SITE_X'], site['SITE_Y'], site['SITE_Z'],\n",
    "                             simplices=simplices,\n",
    "                             title=\"wafare\", aspectratio=dict(x=1, y=1, z=0.5))\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample(i):\n",
    "    pp = create_process_vector(YS[i])\n",
    "    latent_points, labels, _ = generate_latent_points(latent_dim, 1)\n",
    "    del labels\n",
    "    X_test = generator_model.predict([latent_points, pp])\n",
    "    X_test = scaler_x.inverse_transform(X_test.reshape(1,-1))\n",
    "    visualize(X_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# train model\n",
    "n_runs = 64\n",
    "total_batch = 0\n",
    "total_epochs = 0\n",
    "n_batch = 128\n",
    "n_epochs = 16\n",
    "\n",
    "print('train model for ' + str(n_runs * n_epochs))\n",
    "for k in range(n_runs):\n",
    "    print(k)\n",
    "    total_batch = total_batch + (dataset[0].shape[0] / n_batch) * n_epochs\n",
    "    print(total_batch)\n",
    "    train_cgan(generator_model, discriminator_model, GAN, dataset, latent_dim)\n",
    "    \n",
    "    #visualize samples after each run\n",
    "    visualize_sample(0)\n",
    "    visualize_sample(1)\n",
    "    visualize_sample(3)\n",
    "    visualize_sample(4)\n",
    "    \n",
    "\n",
    "    # save models\n",
    "    savename = '7x7_aug_data_5'\n",
    "    generator_model.save(savename+'_total_batches_'+str(total_batch) + '_generator.h5')\n",
    "    discriminator_model.save(savename+'_total_batches_'+str(total_batch) + ' _discriminator.h5')\n",
    "    GAN.save(savename+'_total_batches_'+str(total_batch) + '_gan.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "def save_model(model):\n",
    "    # serialize model to JSON\n",
    "    with open(f\"{model}.json\", \"w\") as json_file:\n",
    "        json_file.write(generator_model.to_json())\n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    generator_model.save_weights(f\"{model}.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "    \n",
    "save_model('generator_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# latent_points, labels, _ = generate_latent_points(latent_dim, 1)\n",
    "visualize_sample(0)\n",
    "# visualize_sample(1)\n",
    "# visualize_sample(3)\n",
    "# visualize_sample(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
